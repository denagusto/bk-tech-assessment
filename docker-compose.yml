version: "3.9"

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: flash_sale
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres-init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d flash_sale"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc -w 2 localhost 2181 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Apache Kafka (dual listeners: in-network + host)
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"    # in-network listener (optional to expose)
      - "29092:29092"  # host-facing listener (use from your laptop)
    environment:
      KAFKA_BROKER_ID: "1"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"

      # Two listeners: containers use kafka:9092; host uses 127.0.0.1:29092
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://127.0.0.1:29092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"

      # Dev-friendly single-broker settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka:9092 --list >/dev/null 2>&1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Redpanda Console - UI for Kafka
  redpanda-console:
    image: redpandadata/console:latest
    depends_on:
      - kafka
    ports:
      - "18080:8080"
    environment:
      CONFIG_FILEPATH: /etc/redpanda-console/redpanda-console-config.yaml
    volumes:
      - ./redpanda-console-config.yaml:/etc/redpanda-console/redpanda-console-config.yaml:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Graylog stack (MongoDB + Elasticsearch)
  mongo:
    image: mongo:6
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--quiet", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.17
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9200/_cluster/health >/dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  graylog:
    image: graylog/graylog:5.2
    depends_on:
      - mongo
      - elasticsearch
    ports:
      - "19000:9000"      # Web UI
      - "19201:12201/udp" # GELF UDP input
      - "19114:1514"      # Syslog TCP input
    environment:
      GRAYLOG_PASSWORD_SECRET: somepasswordpepper
      # admin / admin (SHA-256 of "admin")
      GRAYLOG_ROOT_PASSWORD_SHA2: 8c6976e5b5410415bde908bd4dee15dfb167a9c873fc4bb8a81f6f2ab448a918
      GRAYLOG_HTTP_EXTERNAL_URI: "http://127.0.0.1:19000/"
      GRAYLOG_ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
      GRAYLOG_MONGODB_URI: "mongodb://mongo:27017/graylog"
    volumes:
      - graylog_data:/usr/share/graylog/data
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:9000/api/system/lbstatus"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
  kafka_data:
  graylog_data:
  mongo_data:
  elasticsearch_data:
